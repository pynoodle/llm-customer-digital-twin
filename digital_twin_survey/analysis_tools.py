"""
ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ìœ í‹¸ë¦¬í‹°
ì„¤ë¬¸/ì¸í„°ë·° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë„êµ¬
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict
import json


class SurveyAnalyzer:
    """ì„¤ë¬¸ ê²°ê³¼ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, csv_file: str):
        """
        Args:
            csv_file: ì„¤ë¬¸ ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ
        """
        self.df = pd.read_csv(csv_file)
        self.response_cols = [col for col in self.df.columns 
                             if col.startswith('Q') and not col.endswith('_reasoning')]
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
    
    def basic_statistics(self) -> pd.DataFrame:
        """ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°"""
        stats = self.df[self.response_cols].describe()
        return stats
    
    def distribution_plot(self, save_path: str = None):
        """ì‘ë‹µ ë¶„í¬ ì‹œê°í™”"""
        n_questions = len(self.response_cols)
        fig, axes = plt.subplots(1, n_questions, figsize=(5*n_questions, 4))
        
        if n_questions == 1:
            axes = [axes]
        
        for idx, col in enumerate(self.response_cols):
            # íˆìŠ¤í† ê·¸ë¨
            axes[idx].hist(self.df[col].dropna(), bins=7, range=(0.5, 7.5), 
                          edgecolor='black', alpha=0.7)
            axes[idx].set_xlabel('Response Score')
            axes[idx].set_ylabel('Frequency')
            axes[idx].set_title(f'{col} Distribution')
            axes[idx].set_xticks(range(1, 8))
            axes[idx].grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ë¶„í¬ ì°¨íŠ¸ ì €ì¥: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def correlation_heatmap(self, save_path: str = None):
        """ì§ˆë¬¸ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"""
        if len(self.response_cols) < 2:
            print("âš ï¸ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        corr_matrix = self.df[self.response_cols].corr()
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=1, cbar_kws={"shrink": 0.8})
        plt.title('Question Correlation Matrix', fontsize=14, pad=20)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ìƒê´€ê´€ê³„ ì°¨íŠ¸ ì €ì¥: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def response_patterns(self) -> Dict:
        """ì‘ë‹µ íŒ¨í„´ ë¶„ì„"""
        patterns = {
            'high_scorers': [],  # í‰ê·  6 ì´ìƒ
            'low_scorers': [],   # í‰ê·  3 ì´í•˜
            'neutral': [],       # í‰ê·  3-6
            'consistent': [],    # í‘œì¤€í¸ì°¨ < 1
            'variable': []       # í‘œì¤€í¸ì°¨ >= 2
        }
        
        for idx, row in self.df.iterrows():
            scores = row[self.response_cols].dropna()
            mean_score = scores.mean()
            std_score = scores.std()
            
            pid = row.get('participant_id', f'P{idx}')
            
            if mean_score >= 6:
                patterns['high_scorers'].append(pid)
            elif mean_score <= 3:
                patterns['low_scorers'].append(pid)
            else:
                patterns['neutral'].append(pid)
            
            if std_score < 1:
                patterns['consistent'].append(pid)
            elif std_score >= 2:
                patterns['variable'].append(pid)
        
        return patterns
    
    def summary_report(self) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("="*80)
        report.append("ğŸ“Š ì„¤ë¬¸ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("="*80)
        report.append("")
        
        # ê¸°ë³¸ ì •ë³´
        report.append(f"ì‘ë‹µì ìˆ˜: {len(self.df)}ëª…")
        report.append(f"ì§ˆë¬¸ ìˆ˜: {len(self.response_cols)}ê°œ")
        report.append("")
        
        # ì§ˆë¬¸ë³„ í†µê³„
        report.append("ì§ˆë¬¸ë³„ í†µê³„:")
        report.append("-"*80)
        for col in self.response_cols:
            data = self.df[col].dropna()
            report.append(f"\n{col}:")
            report.append(f"  í‰ê· : {data.mean():.2f}")
            report.append(f"  ì¤‘ì•™ê°’: {data.median():.1f}")
            report.append(f"  í‘œì¤€í¸ì°¨: {data.std():.2f}")
            report.append(f"  ìµœë¹ˆê°’: {data.mode()[0] if len(data.mode()) > 0 else 'N/A'}")
            
            # ë¶„í¬
            value_counts = data.value_counts().sort_index()
            report.append(f"  ë¶„í¬: {dict(value_counts)}")
        
        report.append("")
        
        # ì‘ë‹µ íŒ¨í„´
        patterns = self.response_patterns()
        report.append("ì‘ë‹µ íŒ¨í„´:")
        report.append("-"*80)
        report.append(f"ê¸ì •ì  ì‘ë‹µì (í‰ê·  â‰¥6): {len(patterns['high_scorers'])}ëª…")
        report.append(f"ë¶€ì •ì  ì‘ë‹µì (í‰ê·  â‰¤3): {len(patterns['low_scorers'])}ëª…")
        report.append(f"ì¼ê´€ì  ì‘ë‹µì (í‘œì¤€í¸ì°¨ <1): {len(patterns['consistent'])}ëª…")
        report.append(f"ë³€ë™ì  ì‘ë‹µì (í‘œì¤€í¸ì°¨ â‰¥2): {len(patterns['variable'])}ëª…")
        
        report.append("")
        report.append("="*80)
        
        return "\n".join(report)


class InterviewAnalyzer:
    """ì¸í„°ë·° ê²°ê³¼ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, csv_file: str):
        """
        Args:
            csv_file: ì¸í„°ë·° ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ
        """
        self.df = pd.read_csv(csv_file)
        self.response_cols = [col for col in self.df.columns 
                             if col.startswith('Q')]
    
    def word_frequency(self, question_col: str, top_n: int = 20) -> pd.DataFrame:
        """íŠ¹ì • ì§ˆë¬¸ì˜ ë‹¨ì–´ ë¹ˆë„ ë¶„ì„"""
        from collections import Counter
        import re
        
        # ëª¨ë“  ì‘ë‹µ í•©ì¹˜ê¸°
        all_text = ' '.join(self.df[question_col].dropna().astype(str))
        
        # ë‹¨ì–´ ì¶”ì¶œ (ì•ŒíŒŒë²³ë§Œ)
        words = re.findall(r'\b[a-zA-Z]{3,}\b', all_text.lower())
        
        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = set(['the', 'and', 'that', 'this', 'with', 'for', 'are', 'was', 
                         'but', 'not', 'you', 'all', 'can', 'her', 'has', 'had', 
                         'have', 'what', 'when', 'where', 'who', 'will', 'would'])
        
        words = [w for w in words if w not in stop_words]
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = Counter(words)
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        freq_df = pd.DataFrame(word_freq.most_common(top_n), 
                              columns=['Word', 'Frequency'])
        
        return freq_df
    
    def response_length_analysis(self) -> pd.DataFrame:
        """ì‘ë‹µ ê¸¸ì´ ë¶„ì„"""
        length_data = []
        
        for col in self.response_cols:
            lengths = self.df[col].dropna().apply(lambda x: len(str(x).split()))
            length_data.append({
                'Question': col,
                'Avg_Words': lengths.mean(),
                'Min_Words': lengths.min(),
                'Max_Words': lengths.max(),
                'Std_Words': lengths.std()
            })
        
        return pd.DataFrame(length_data)
    
    def sentiment_indicators(self) -> pd.DataFrame:
        """ê°„ë‹¨í•œ ê°ì„± ì§€í‘œ (ê¸ì •/ë¶€ì • ë‹¨ì–´ ë¹ˆë„)"""
        positive_words = set(['good', 'great', 'excellent', 'love', 'enjoy', 'happy', 
                             'satisfied', 'amazing', 'wonderful', 'fantastic', 'positive'])
        negative_words = set(['bad', 'poor', 'terrible', 'hate', 'dislike', 'unhappy', 
                             'dissatisfied', 'awful', 'horrible', 'negative'])
        
        sentiment_data = []
        
        for col in self.response_cols:
            pos_count = 0
            neg_count = 0
            
            for response in self.df[col].dropna():
                words = response.lower().split()
                pos_count += sum(1 for w in words if w in positive_words)
                neg_count += sum(1 for w in words if w in negative_words)
            
            sentiment_data.append({
                'Question': col,
                'Positive_Words': pos_count,
                'Negative_Words': neg_count,
                'Sentiment_Ratio': pos_count / (neg_count + 1)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            })
        
        return pd.DataFrame(sentiment_data)
    
    def summary_report(self) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("="*80)
        report.append("ğŸ¤ ì¸í„°ë·° ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("="*80)
        report.append("")
        
        # ê¸°ë³¸ ì •ë³´
        report.append(f"ì‘ë‹µì ìˆ˜: {len(self.df)}ëª…")
        report.append(f"ì§ˆë¬¸ ìˆ˜: {len(self.response_cols)}ê°œ")
        report.append("")
        
        # ì‘ë‹µ ê¸¸ì´ ë¶„ì„
        length_df = self.response_length_analysis()
        report.append("ì‘ë‹µ ê¸¸ì´ ë¶„ì„:")
        report.append("-"*80)
        report.append(length_df.to_string(index=False))
        report.append("")
        
        # ê°ì„± ë¶„ì„
        sentiment_df = self.sentiment_indicators()
        report.append("ê°ì„± ì§€í‘œ:")
        report.append("-"*80)
        report.append(sentiment_df.to_string(index=False))
        report.append("")
        
        # ê° ì§ˆë¬¸ë³„ ì£¼ìš” ë‹¨ì–´
        report.append("ì§ˆë¬¸ë³„ ì£¼ìš” í‚¤ì›Œë“œ (Top 10):")
        report.append("-"*80)
        for col in self.response_cols:
            report.append(f"\n{col}:")
            freq_df = self.word_frequency(col, top_n=10)
            for _, row in freq_df.iterrows():
                report.append(f"  {row['Word']}: {row['Frequency']}íšŒ")
        
        report.append("")
        report.append("="*80)
        
        return "\n".join(report)


def analyze_survey_file(csv_file: str, output_prefix: str):
    """ì„¤ë¬¸ ê²°ê³¼ íŒŒì¼ ë¶„ì„ ì‹¤í–‰"""
    print(f"\nğŸ“Š ì„¤ë¬¸ ê²°ê³¼ ë¶„ì„: {csv_file}")
    print("="*80)
    
    analyzer = SurveyAnalyzer(csv_file)
    
    # ê¸°ë³¸ í†µê³„
    print("\nê¸°ë³¸ í†µê³„:")
    print(analyzer.basic_statistics())
    
    # ë¶„í¬ ì°¨íŠ¸
    analyzer.distribution_plot(f"{output_prefix}_distribution.png")
    
    # ìƒê´€ê´€ê³„ (ì§ˆë¬¸ì´ 2ê°œ ì´ìƒì¼ ë•Œ)
    if len(analyzer.response_cols) >= 2:
        analyzer.correlation_heatmap(f"{output_prefix}_correlation.png")
    
    # ì¢…í•© ë¦¬í¬íŠ¸
    report = analyzer.summary_report()
    print("\n" + report)
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(f"{output_prefix}_report.txt", 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥: {output_prefix}_report.txt")


def analyze_interview_file(csv_file: str, output_prefix: str):
    """ì¸í„°ë·° ê²°ê³¼ íŒŒì¼ ë¶„ì„ ì‹¤í–‰"""
    print(f"\nğŸ¤ ì¸í„°ë·° ê²°ê³¼ ë¶„ì„: {csv_file}")
    print("="*80)
    
    analyzer = InterviewAnalyzer(csv_file)
    
    # ì¢…í•© ë¦¬í¬íŠ¸
    report = analyzer.summary_report()
    print("\n" + report)
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(f"{output_prefix}_report.txt", 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥: {output_prefix}_report.txt")


def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ“ˆ ì„¤ë¬¸/ì¸í„°ë·° ê²°ê³¼ ë¶„ì„ ë„êµ¬")
    print("="*80)
    
    # íŒŒì¼ ì„ íƒ
    print("\në¶„ì„í•  íŒŒì¼ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì„¤ë¬¸ì¡°ì‚¬ ê²°ê³¼ (Survey)")
    print("2. ì¸í„°ë·° ê²°ê³¼ (Interview)")
    
    choice = input("\nì„ íƒ (1-2): ").strip()
    
    csv_file = input("CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    output_prefix = input("ì¶œë ¥ íŒŒì¼ëª… ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: analysis): ").strip() or "analysis"
    
    try:
        if choice == "1":
            analyze_survey_file(csv_file, output_prefix)
        elif choice == "2":
            analyze_interview_file(csv_file, output_prefix)
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
