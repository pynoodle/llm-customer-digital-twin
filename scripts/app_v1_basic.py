"""
ë””ì§€í„¸ íŠ¸ìœˆ ì„¤ë¬¸ì¡°ì‚¬ & ì¸í„°ë·° ì‹œìŠ¤í…œ
Streamlit GUI ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import os
import pandas as pd
from dotenv import load_dotenv
from src.dataset_loader import DatasetLoader
from src.ai_agent import AIAgent
from block_based_selector import BlockBasedSelector

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LLM Customer Digital Twin",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì—ëŸ¬ ë¬´ì‹œ)
try:
    load_dotenv()
except:
    pass  # .env íŒŒì¼ì´ ì—†ê±°ë‚˜ ì˜ëª»ë˜ì–´ë„ ê³„ì† ì§„í–‰

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .warning-box {
        background-color: #fff3e0;
        padding: 1rem;
        border-radius: 8px;
        border-left: 5px solid #ff9800;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False
    
    if 'loader' not in st.session_state:
        st.session_state.loader = None
    
    if 'ai_agent' not in st.session_state:
        st.session_state.ai_agent = None
    
    if 'block_selector' not in st.session_state:
        st.session_state.block_selector = None
    
    if 'selected_personas' not in st.session_state:
        st.session_state.selected_personas = []
    
    if 'survey_responses' not in st.session_state:
        st.session_state.survey_responses = []
    
    if 'interview_results' not in st.session_state:
        st.session_state.interview_results = []
    
    if 'api_key' not in st.session_state:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
        api_key = os.getenv("OPENAI_API_KEY", "")
        st.session_state.api_key = api_key


def check_api_key():
    """API í‚¤ë¥¼ í™•ì¸í•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤."""
    # API í‚¤ê°€ ì´ë¯¸ ì„¸ì…˜ì— ìˆìœ¼ë©´ í†µê³¼
    if st.session_state.api_key and len(st.session_state.api_key) > 20:
        return True
    
    st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with st.expander("API í‚¤ ì„¤ì • ë°©ë²•", expanded=True):
        st.markdown("""
        **API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”**
        """)
        
        api_key_input = st.text_input(
            "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            type="password",
            key="api_key_input",
            value=""
        )
        
        if st.button("API í‚¤ ì €ì¥"):
            if api_key_input:
                st.session_state.api_key = api_key_input
                st.success("âœ… API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    return False


def initialize_system():
    """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if st.session_state.initialized:
        return True
    
    if not check_api_key():
        return False
    
    with st.spinner("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
        try:
            # ë°ì´í„°ì…‹ ë¡œë” ì´ˆê¸°í™”
            if st.session_state.loader is None:
                loader = DatasetLoader()
                loader.load()
                st.session_state.loader = loader
            
            # AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
            if st.session_state.ai_agent is None:
                agent = AIAgent(api_key=st.session_state.api_key)
                st.session_state.ai_agent = agent
            
            # ë¸”ë¡ ê¸°ë°˜ ì„ íƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if st.session_state.block_selector is None:
                try:
                    # ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì¶œë ¥ì„ ìº¡ì²˜
                    import io
                    import contextlib
                    
                    # ì¶œë ¥ ìº¡ì²˜
                    captured_output = io.StringIO()
                    with contextlib.redirect_stdout(captured_output):
                        with contextlib.redirect_stderr(captured_output):
                            block_selector = BlockBasedSelector()
                            block_selector.load()
                    
                    st.session_state.block_selector = block_selector
                except Exception as e:
                    st.warning(f"âš ï¸ ë¸”ë¡ ê¸°ë°˜ ì„ íƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            st.session_state.initialized = True
            return True
            
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    initialize_session_state()
    
    # í—¤ë”
    st.markdown(
        '<div style="text-align: center; color: #999; font-size: 0.9rem; margin-bottom: 0.5rem;">LLM Customer Digital Twin</div>',
        unsafe_allow_html=True
    )
    st.markdown('<div class="main-header">ğŸ¤– ç¾ ê³ ê° ë””ì§€í„¸ íŠ¸ìœˆ</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-header">AI ê¸°ë°˜ ì„¤ë¬¸ì¡°ì‚¬ & ì¸í„°ë·° í”Œë«í¼</div>',
        unsafe_allow_html=True
    )
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if not initialize_system():
        st.stop()
    
    # ì´ˆê¸°í™” ì„±ê³µ ë©”ì‹œì§€
    st.success("âœ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # í†µê³„ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    
    total_personas = len(st.session_state.loader.get_all_personas())
    selected = len(st.session_state.selected_personas)
    survey_count = len(st.session_state.survey_responses)
    interview_count = len(st.session_state.interview_results)
    
    with col1:
        st.metric("ì „ì²´ í˜ë¥´ì†Œë‚˜", f"{total_personas:,}")
    
    with col2:
        st.metric("ì„ íƒëœ ì‘ë‹µì", selected)
    
    with col3:
        st.metric("ì„¤ë¬¸ ì‘ë‹µ", survey_count)
    
    with col4:
        st.metric("ì¸í„°ë·° ì™„ë£Œ", interview_count)
    
    st.divider()
    
    # ì£¼ìš” ê¸°ëŠ¥ ì†Œê°œ
    st.markdown("## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        with st.container():
            st.markdown("### ğŸ“Š ì„¤ë¬¸ì¡°ì‚¬")
            st.markdown("""
            - **1-7ì  ë¦¬ì»¤íŠ¸ ì²™ë„** ì‘ë‹µ
            - êµ¬ì¡°í™”ëœ ì§ˆë¬¸ ê´€ë¦¬
            - ìë™ í†µê³„ ë¶„ì„
            - ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
            """)
        
        st.markdown("")
        
        with st.container():
            st.markdown("### ğŸ¯ ì‘ë‹µì ì„ íƒ")
            st.markdown("""
            - ë¬´ì‘ìœ„ ìƒ˜í”Œë§
            - ì¡°ê±´ ê¸°ë°˜ í•„í„°ë§
            - ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥
            - ID ì§ì ‘ ì„ íƒ
            """)
    
    with col2:
        with st.container():
            st.markdown("### ğŸ’¬ ì¸í„°ë·°")
            st.markdown("""
            - ê°œë°©í˜• ì§ˆë¬¸ ì‘ë‹µ
            - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
            - ì¸í„°ë·°ë¡ ìë™ ìƒì„±
            - ì‹¬ì¸µ ë¶„ì„ ì§€ì›
            """)
        
        st.markdown("")
        
        with st.container():
            st.markdown("### ğŸ“ ê²°ê³¼ ê´€ë¦¬")
            st.markdown("""
            - JSON, CSV, Excel í˜•ì‹
            - ì‹¤ì‹œê°„ ì‹œê°í™”
            - í†µê³„ ìë™ ê³„ì‚°
            - ì¸í„°ë·°ë¡ ë‹¤ìš´ë¡œë“œ
            """)

    
    st.divider()
    
    # ì‹œì‘ ê°€ì´ë“œ
    st.markdown("## ğŸš€ ì‹œì‘í•˜ê¸°")
    
    st.markdown("""
    1. **ì™¼ìª½ ì‚¬ì´ë“œë°”**ì—ì„œ ì›í•˜ëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”
    2. **ì‘ë‹µì ì„ íƒ** í˜ì´ì§€ì—ì„œ ì—°êµ¬ ëŒ€ìƒì„ ì„ íƒí•©ë‹ˆë‹¤
    3. **ì„¤ë¬¸ì¡°ì‚¬** ë˜ëŠ” **ì¸í„°ë·°** í˜ì´ì§€ì—ì„œ ì—°êµ¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤
    4. **ê²°ê³¼ ë³´ê¸°** í˜ì´ì§€ì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤
    """)
    
    # ê²½ê³  ë©”ì‹œì§€
    if not st.session_state.selected_personas:
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.warning("âš ï¸ ì•„ì§ ì‘ë‹µìë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ì‘ë‹µì ì„ íƒ' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”.")
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.divider()
    
    # ë°ì´í„°ì…‹ ì •ë³´
    with st.expander("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´", expanded=False):
        st.markdown("### Twin-2K-500 ë°ì´í„°ì…‹")
        st.markdown("""
        - **ì¶œì²˜**: [Hugging Face - LLM-Digital-Twin](https://huggingface.co/datasets/LLM-Digital-Twin/Twin-2K-500)
        - **ì°¸ê°€ì**: 2,058ëª…ì˜ ë””ì§€í„¸ íŠ¸ìœˆ
        - **ì„¤ëª…**: ì‹¤ì œ ì‚¬ëŒë“¤ì˜ 500ê°œ ì´ìƒ ì§ˆë¬¸ ì‘ë‹µ ë°ì´í„° ê¸°ë°˜
        - **í™œìš©**: AI ê¸°ë°˜ ì„¤ë¬¸ì¡°ì‚¬ ë° ì¸í„°ë·° ì‹œë®¬ë ˆì´ì…˜
        """)
        
        st.divider()
        
        if st.session_state.loader:
            # ê¸°ì¡´ ë°ì´í„°ì…‹ ì •ë³´
            categorized = st.session_state.loader.get_categorized_fields()
            
            # ë¸”ë¡ ê¸°ë°˜ ë°ì´í„°ì…‹ ì •ë³´ ì¶”ê°€
            if st.session_state.block_selector:
                st.markdown("### ğŸ¯ ë¸”ë¡ ê¸°ë°˜ ì„¤ë¬¸ëŒ€ìƒ ì„ ì •")
                st.markdown("ë¸”ë¡ë³„ íŠ¹ì„±ì„ í™œìš©í•œ ì •ë°€í•œ ì‘ë‹µì ì„ ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                
                # ë¸”ë¡ í†µê³„ í‘œì‹œ
                block_stats = st.session_state.block_selector.get_block_statistics()
                if block_stats:
                    st.markdown("#### ğŸ“Š ì£¼ìš” ë¸”ë¡ ë¶„í¬")
                    
                    # ë¸”ë¡ ì„¤ëª… ë§¤í•‘
                    block_descriptions = {
                        "Demographics": "ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„± (ë‚˜ì´, ì„±ë³„, ì§€ì—­ ë“±)",
                        "Personality": "ì„±ê²© íŠ¹ì„± ë° ì‹¬ë¦¬ì  íŠ¹ì„±",
                        "Cognitive Tests": "ì¸ì§€ëŠ¥ë ¥ ë° ì‚¬ê³ ë ¥ í…ŒìŠ¤íŠ¸",
                        "Economic Preferences": "ê²½ì œì  ì„ í˜¸ë„ ë° ì˜ì‚¬ê²°ì •",
                        "Product Preferences - Pricing": "ì œí’ˆ ê°€ê²© ì„ í˜¸ë„",
                        "False Consensus": "ê±°ì§“ í•©ì˜ íš¨ê³¼ ì‹¤í—˜",
                        "Base Rate 70 Engineers": "ê¸°ë³¸ë¥  ì˜¤ë¥˜ ì‹¤í—˜ (70ëª… ì—”ì§€ë‹ˆì–´)",
                        "Base Rate 30 Engineers": "ê¸°ë³¸ë¥  ì˜¤ë¥˜ ì‹¤í—˜ (30ëª… ì—”ì§€ë‹ˆì–´)",
                        "Disease Loss": "ì§ˆë³‘ ì†ì‹¤ í”„ë ˆì´ë° ì‹¤í—˜",
                        "Disease Gain": "ì§ˆë³‘ ì´ìµ í”„ë ˆì´ë° ì‹¤í—˜",
                        "Anchoring - African Countries High": "ì•µì»¤ë§ íš¨ê³¼ (ì•„í”„ë¦¬ì¹´ êµ­ê°€ - ë†’ì€ ì•µì»¤)",
                        "Anchoring - African Countries Low": "ì•µì»¤ë§ íš¨ê³¼ (ì•„í”„ë¦¬ì¹´ êµ­ê°€ - ë‚®ì€ ì•µì»¤)",
                        "Anchoring - Redwood High": "ì•µì»¤ë§ íš¨ê³¼ (ì„¸ì¿¼ì´ì•„ - ë†’ì€ ì•µì»¤)",
                        "Anchoring - Redwood Low": "ì•µì»¤ë§ íš¨ê³¼ (ì„¸ì¿¼ì´ì•„ - ë‚®ì€ ì•µì»¤)",
                        "Outcome Bias - Success": "ê²°ê³¼ í¸í–¥ (ì„±ê³µ ì‚¬ë¡€)",
                        "Outcome Bias - Failure": "ê²°ê³¼ í¸í–¥ (ì‹¤íŒ¨ ì‚¬ë¡€)",
                        "Sunk Cost - Yes": "ë§¤ëª°ë¹„ìš© íš¨ê³¼ (ì˜ˆ)",
                        "Sunk Cost - No": "ë§¤ëª°ë¹„ìš© íš¨ê³¼ (ì•„ë‹ˆì˜¤)",
                        "Allais Form 1": "ì•¨ë¦¬ìŠ¤ íŒ¨ëŸ¬ë…ìŠ¤ (í˜•íƒœ 1)",
                        "Allais Form 2": "ì•¨ë¦¬ìŠ¤ íŒ¨ëŸ¬ë…ìŠ¤ (í˜•íƒœ 2)",
                        "Linda Conjunction": "ë¦°ë‹¤ ë¬¸ì œ (ì—°ì ‘)",
                        "Linda -No Conjunction": "ë¦°ë‹¤ ë¬¸ì œ (ë¹„ì—°ì ‘)",
                        "Myside German": "ë‚´ í¸í–¥ (ë…ì¼ ê´€ë ¨)",
                        "Myside Ford": "ë‚´ í¸í–¥ (í¬ë“œ ê´€ë ¨)",
                        "Probability Matching vs. Maximizing - Problem 1": "í™•ë¥  ë§¤ì¹­ vs ìµœëŒ€í™” (ë¬¸ì œ 1)",
                        "Probability Matching vs. Maximizing - Problem 2": "í™•ë¥  ë§¤ì¹­ vs ìµœëŒ€í™” (ë¬¸ì œ 2)",
                        "Less is More Gamble A": "ëœì´ ë” íš¨ê³¼ (ê²Œì„ A)",
                        "Less is More Gamble B": "ëœì´ ë” íš¨ê³¼ (ê²Œì„ B)",
                        "Less is More Gamble C": "ëœì´ ë” íš¨ê³¼ (ê²Œì„ C)",
                        "Proportion Dominance 1A": "ë¹„ìœ¨ ì§€ë°° (1A)",
                        "Proportion Dominance 1B": "ë¹„ìœ¨ ì§€ë°° (1B)",
                        "Proportion Dominance 1C": "ë¹„ìœ¨ ì§€ë°° (1C)",
                        "Proportion Dominance 2A": "ë¹„ìœ¨ ì§€ë°° (2A)",
                        "Proportion Dominance 2B": "ë¹„ìœ¨ ì§€ë°° (2B)",
                        "Proportion Dominance 2C": "ë¹„ìœ¨ ì§€ë°° (2C)",
                        "WTA/WTP Thaler Problem - WTA Certainty": "ì§€ë¶ˆì˜ì‚¬/ìˆ˜ìš©ì˜ì‚¬ (í™•ì‹¤ì„±)",
                        "WTA/WTP Thaler Problem - WTP Certainty": "ì§€ë¶ˆì˜ì‚¬/ìˆ˜ìš©ì˜ì‚¬ (í™•ì‹¤ì„±)",
                        "WTA/WTP Thaler - WTP Noncertainty": "ì§€ë¶ˆì˜ì‚¬/ìˆ˜ìš©ì˜ì‚¬ (ë¶ˆí™•ì‹¤ì„±)",
                        "Absolute vs. Relative - Calculator": "ì ˆëŒ€ vs ìƒëŒ€ (ê³„ì‚°ê¸°)",
                        "Absolute vs. Relative - Jacket": "ì ˆëŒ€ vs ìƒëŒ€ (ì¬í‚·)",
                        "Non-Experimental Heuristics and Biases": "ë¹„ì‹¤í—˜ì  íœ´ë¦¬ìŠ¤í‹± ë° í¸í–¥",
                        "Forward Flow": "ìˆœë°©í–¥ íë¦„"
                    }
                    
                    # ìƒìœ„ 10ê°œ ë¸”ë¡ í‘œì‹œ
                    sorted_stats = sorted(block_stats.items(), key=lambda x: x[1]['presence_rate'], reverse=True)
                    
                    for i, (block_name, stat) in enumerate(sorted_stats[:10]):
                        description = block_descriptions.get(block_name, "ì‹¬ë¦¬í•™/í–‰ë™ê²½ì œí•™ ì‹¤í—˜")
                        
                        with st.expander(f"**{block_name}** ({stat['presence_rate']:.1f}%)", expanded=(i < 3)):
                            st.write(f"**ì„¤ëª…**: {description}")
                            st.write(f"**ì°¸ì—¬ì ìˆ˜**: {stat['presence_count']:,}ëª…")
                            if stat['avg_questions'] > 0:
                                st.write(f"**í‰ê·  ì§ˆë¬¸ ìˆ˜**: {stat['avg_questions']:.1f}ê°œ")
                    
                    st.caption("ğŸ’¡ 'ì‘ë‹µì ì„ íƒ' í˜ì´ì§€ì—ì„œ ë¸”ë¡ ê¸°ë°˜ í•„í„°ë§ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                st.divider()
            
            if categorized:
                st.markdown("### ğŸ“‚ ë°ì´í„° ì¹´í…Œê³ ë¦¬ êµ¬ì„±")
                st.markdown("ì‘ë‹µìë¥¼ í•„í„°ë§í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤.")
                st.markdown("")
                
                # ì¹´í…Œê³ ë¦¬ë³„ ì„¤ëª…ê³¼ í•„ë“œ ìˆ˜
                category_info = {
                    "ì¸êµ¬í†µê³„": ("ğŸ“Š", "ë‚˜ì´, ì„±ë³„, ì¸ì¢… ë“± ê¸°ë³¸ ì¸êµ¬í†µê³„í•™ì  ì •ë³´"),
                    "ì§ì—…ê²½ì œ": ("ğŸ’¼", "ì§ì—…, ì‚°ì—…, ì†Œë“, ê³ ìš© ìƒíƒœ ë“±"),
                    "êµìœ¡": ("ğŸ“", "í•™ë ¥, ì „ê³µ, í•™êµ ë“± êµìœ¡ ê´€ë ¨ ì •ë³´"),
                    "ì„±ê²©ì‹¬ë¦¬": ("ğŸ§ ", "ì„±ê²© íŠ¹ì„±, Big Five ì§€í‘œ ë“±"),
                    "ê²½ì œíŠ¹ì„±": ("ğŸ’°", "ì¬ì • ìƒíƒœ, ìì‚°, ì†Œë¹„ íŒ¨í„´ ë“±"),
                    "ë¼ì´í”„ìŠ¤íƒ€ì¼": ("ğŸ ", "ì·¨ë¯¸, ê´€ì‹¬ì‚¬, ê±´ê°•, ì—¬ê°€ í™œë™ ë“±"),
                    "ì§€ë¦¬ìœ„ì¹˜": ("ğŸŒ", "ê±°ì£¼ì§€, ë„ì‹œ, ì§€ì—­ ë“±"),
                    "ê´€ê³„ê°€ì¡±": ("â¤ï¸", "ê²°í˜¼ ìƒíƒœ, ìë…€, ê°€ì¡± êµ¬ì„± ë“±"),
                    "ê°€ì¹˜ê´€íƒœë„": ("ğŸ¯", "ì„¤ë¬¸ ì‘ë‹µ ë°ì´í„° (question_1~31)"),
                    "ê¸°ìˆ ë¯¸ë””ì–´": ("ğŸ“±", "ê¸°ìˆ  ì‚¬ìš©, SNS, ë””ì§€í„¸ ë¦¬í„°ëŸ¬ì‹œ ë“±"),
                    "ê¸°íƒ€": ("ğŸ”¢", "ê¸°íƒ€ ë¶„ë¥˜ë˜ì§€ ì•Šì€ í•„ë“œ")
                }
                
                for category, fields in categorized.items():
                    emoji, description = category_info.get(category, ("ğŸ“‚", ""))
                    
                    with st.container():
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            st.markdown(f"**{emoji} {category}**")
                            st.caption(description)
                        
                        with col2:
                            st.metric("í•„ë“œ ìˆ˜", len(fields))
                        
                        # ì²˜ìŒ 5ê°œ í•„ë“œë§Œ í‘œì‹œ
                        with st.expander(f"í•„ë“œ ëª©ë¡ ë³´ê¸° ({len(fields)}ê°œ)", expanded=False):
                            for i, field in enumerate(fields[:10], 1):
                                st.text(f"{i}. {field}")
                            if len(fields) > 10:
                                st.caption(f"... ì™¸ {len(fields) - 10}ê°œ")
                
                st.divider()
                
                # ì „ì²´ í†µê³„
                total_fields = sum(len(f) for f in categorized.values())
                st.success(f"âœ… ì´ **{total_fields}ê°œ**ì˜ í•„ë“œë¡œ ì‘ë‹µì í•„í„°ë§ ê°€ëŠ¥")
            
            st.divider()
            
            # ìƒ˜í”Œ í˜ë¥´ì†Œë‚˜ ë¯¸ë¦¬ë³´ê¸°
            if st.session_state.loader.personas:
                st.markdown("### ğŸ‘¤ ìƒ˜í”Œ í˜ë¥´ì†Œë‚˜ ë°ì´í„°")
                st.caption("ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ì˜ ë°ì´í„° ì˜ˆì‹œì…ë‹ˆë‹¤.")
                
                sample_persona = st.session_state.loader.personas[0]
                
                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œ ì°¾ê¸°
                available_fields = []
                for key, value in sample_persona.data.items():
                    if value and str(value).strip() and key not in ['persona_text', 'persona_summary', 'persona_json']:
                        available_fields.append(key)
                
                # ì²˜ìŒ 10ê°œ í•„ë“œë§Œ í‘œì‹œ
                display_fields = available_fields[:10]
                
                if display_fields:
                    sample_data = {}
                    for field in display_fields:
                        value = sample_persona.data[field]
                        # ë„ˆë¬´ ê¸´ ê°’ì€ ì˜ë¼ëƒ„
                        if isinstance(value, str) and len(value) > 100:
                            value = value[:100] + "..."
                        sample_data[field] = value
                    
                    df_sample = pd.DataFrame([sample_data]).T
                    df_sample.columns = ['ê°’']
                    st.dataframe(df_sample, use_container_width=True)
                    
                    if len(available_fields) > 10:
                        st.caption(f"ì´ {len(available_fields)}ê°œ í•„ë“œ ì¤‘ ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ")
                else:
                    # ëª¨ë“  ë°ì´í„° í‘œì‹œ (ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŒ)
                    st.info("ì£¼ìš” í•„ë“œê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                    all_data = {}
                    for key, value in sample_persona.data.items():
                        if value and str(value).strip():
                            if isinstance(value, str) and len(value) > 50:
                                value = value[:50] + "..."
                            all_data[key] = value
                    
                    if all_data:
                        df_all = pd.DataFrame([all_data]).T
                        df_all.columns = ['ê°’']
                        st.dataframe(df_all, use_container_width=True)
                    else:
                        st.info("ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë„ì›€ë§
    with st.expander("â“ ë„ì›€ë§", expanded=False):
        st.markdown("""
        ### ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
        
        **Q: API ë¹„ìš©ì€ ì–¼ë§ˆë‚˜ ë“œë‚˜ìš”?**  
        A: GPT-4o-mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìš©ì„ ìµœì†Œí™”í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µë‹¹ ì•½ $0.001-0.002 ì •ë„ì…ë‹ˆë‹¤.
        
        **Q: ì‘ë‹µ ì‹œê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?**  
        A: ì‘ë‹µì 1ëª…ë‹¹ ì•½ 1-2ì´ˆê°€ ì†Œìš”ë©ë‹ˆë‹¤. ì§€ì—° ì‹œê°„ì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        **Q: ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ì €ì¥í•˜ë‚˜ìš”?**  
        A: 'ê²°ê³¼ ë³´ê¸°' í˜ì´ì§€ì—ì„œ JSON, CSV, Excel í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        **Q: ì„¤ë¬¸ì¡°ì‚¬ í…œí”Œë¦¿ì„ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?**  
        A: ì˜ˆ, ì„¤ë¬¸ì¡°ì‚¬ì™€ ì¸í„°ë·° ê°€ì´ë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥/ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)
    
    st.divider()
    
    # í‘¸í„°
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 2rem;'>
        <p>Powered by OpenAI GPT-4o-mini | Hugging Face Twin-2K-500</p>
        <p>ğŸ¤– LLM Customer Digital Twin System</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()



