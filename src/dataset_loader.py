"""
Twin-2K-500 ë°ì´í„°ì…‹ ë¡œë”
ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import os


@dataclass
class Persona:
    """ë””ì§€í„¸ íŠ¸ìœˆ í˜ë¥´ì†Œë‚˜ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    data: Dict[str, Any]
    
    def __repr__(self):
        return f"Persona(id={self.id})"
    
    def get_summary(self) -> str:
        """í˜ë¥´ì†Œë‚˜ì˜ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        summary_parts = []
        
        # ì£¼ìš” í•„ë“œë§Œ í‘œì‹œ
        key_fields = ['persona_text', 'persona_summary']
        
        for field in key_fields:
            if field in self.data and self.data[field]:
                value = str(self.data[field])
                if len(value) > 200:
                    value = value[:200] + "..."
                summary_parts.append(f"{field.capitalize()}: {value}")
        
        return "\n".join(summary_parts) if summary_parts else "No summary available"


class DatasetLoader:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ë¡œë”"""
    
    def __init__(self, csv_path: str = "processed_dataset/twin2k500_processed.csv"):
        self.csv_path = csv_path
        self.df = None
        self.personas = []
        self.stats = None
    
    def load(self, subset: str = "full_persona") -> None:
        """ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print(f"Loading processed dataset: {self.csv_path}...")
        
        if not os.path.exists(self.csv_path):
            print(f"[ERROR] Processed dataset not found: {self.csv_path}")
            print("[INFO] Please run create_processed_dataset.py first to create the processed dataset.")
            raise FileNotFoundError(f"Processed dataset not found: {self.csv_path}")
        
        try:
            # CSV íŒŒì¼ ë¡œë“œ
            self.df = pd.read_csv(self.csv_path, encoding='utf-8-sig')
            print(f"[OK] Successfully loaded {len(self.df)} personas")
            print(f"[OK] Available columns: {list(self.df.columns)}")
            
            # í†µê³„ ì •ë³´ ë¡œë“œ
            stats_path = os.path.join(os.path.dirname(self.csv_path), "dataset_stats.json")
            if os.path.exists(stats_path):
                with open(stats_path, 'r', encoding='utf-8') as f:
                    self.stats = json.load(f)
                print(f"[OK] Statistics loaded")
            
            # í˜ë¥´ì†Œë‚˜ ê°ì²´ ìƒì„±
            self._create_personas()
            
        except Exception as e:
            print(f"[ERROR] Failed to load dataset: {e}")
            raise
    
    def _create_personas(self) -> None:
        """DataFrameì—ì„œ í˜ë¥´ì†Œë‚˜ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        self.personas = []
        
        for idx, row in self.df.iterrows():
            persona_data = row.to_dict()
            persona_id = str(persona_data.get('id', idx))
            
            persona = Persona(id=persona_id, data=persona_data)
            self.personas.append(persona)
        
        print(f"[OK] Created {len(self.personas)} persona objects")
    
    def get_all_personas(self) -> List[Persona]:
        """ëª¨ë“  í˜ë¥´ì†Œë‚˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.personas
    
    def get_persona_by_id(self, persona_id: str) -> Optional[Persona]:
        """IDë¡œ í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        for persona in self.personas:
            if persona.id == persona_id:
                return persona
        return None
    
    def search_personas(self, filters: Dict[str, Any]) -> List[Persona]:
        """í•„í„° ì¡°ê±´ì— ë§ëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        if self.df is None:
            return []
        
        # DataFrameì—ì„œ í•„í„°ë§
        filtered_df = self.df.copy()
        
        for field, value in filters.items():
            if field in filtered_df.columns:
                if isinstance(value, list):
                    filtered_df = filtered_df[filtered_df[field].isin(value)]
                else:
                    filtered_df = filtered_df[filtered_df[field] == value]
        
        # ê²°ê³¼ë¥¼ í˜ë¥´ì†Œë‚˜ ê°ì²´ë¡œ ë³€í™˜
        results = []
        for idx, row in filtered_df.iterrows():
            persona_data = row.to_dict()
            persona_id = str(persona_data.get('id', idx))
            persona = Persona(id=persona_id, data=persona_data)
            results.append(persona)
        
        return results
    
    def get_random_sample(self, n: int = 10, seed: Optional[int] = None) -> List[Persona]:
        """ëœë¤ ìƒ˜í”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        import random
        
        if seed is not None:
            random.seed(seed)
        
        if n >= len(self.personas):
            return self.personas.copy()
        
        return random.sample(self.personas, n)
    
    def get_available_fields(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.df is None:
            return []
        return list(self.df.columns)
    
    def get_categorized_fields(self) -> Dict[str, List[str]]:
        """í•„ë“œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        if self.df is None:
            return {}
        
        all_fields = list(self.df.columns)
        categories = {
            "ê¸°ë³¸ì •ë³´": [],
            "ì§ˆë¬¸ì‘ë‹µ": [],
            "ê¸°íƒ€": []
        }
        
        for field in all_fields:
            field_str = str(field)
            field_lower = field_str.lower()
            
            if field_str in ['id', 'persona_text', 'persona_summary']:
                categories["ê¸°ë³¸ì •ë³´"].append(field_str)
            elif field_str.startswith('question_'):
                categories["ì§ˆë¬¸ì‘ë‹µ"].append(field_str)
            else:
                categories["ê¸°íƒ€"].append(field_str)
        
        return {k: sorted(v) for k, v in categories.items() if v}
    
    def get_field_unique_values(self, field: str) -> List[Any]:
        """íŠ¹ì • í•„ë“œì˜ ê³ ìœ ê°’ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.df is None or field not in self.df.columns:
            return []
        
        unique_values = self.df[field].dropna().unique().tolist()
        return sorted(unique_values)
    
    def get_dataset_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.stats:
            return self.stats
        
        if self.df is None:
            return {}
        
        return {
            'total_records': len(self.df),
            'total_columns': len(self.df.columns),
            'columns': list(self.df.columns)
        }
    
    def get_sample_data(self, n: int = 5) -> List[Dict[str, Any]]:
        """ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.df is None:
            return []
        
        sample_df = self.df.head(n)
        return sample_df.to_dict('records')


def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª DatasetLoader í…ŒìŠ¤íŠ¸")
    
    loader = DatasetLoader()
    try:
        loader.load()
        
        if loader.personas:
            print(f"\nâœ… ë¡œë“œëœ í˜ë¥´ì†Œë‚˜ ìˆ˜: {len(loader.personas)}")
            
            # ìƒ˜í”Œ í˜ë¥´ì†Œë‚˜ ì¶œë ¥
            sample = loader.personas[0]
            print(f"\nğŸ‘¤ ìƒ˜í”Œ í˜ë¥´ì†Œë‚˜ (ID: {sample.id}):")
            print(sample.get_summary())
            
            # í•„ë“œ ì •ë³´
            fields = loader.get_available_fields()
            print(f"\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œ: {len(fields)}ê°œ")
            print(f"í•„ë“œ ëª©ë¡: {fields}")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í•„ë“œ
            categorized = loader.get_categorized_fields()
            print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ í•„ë“œ:")
            for category, field_list in categorized.items():
                print(f"  {category}: {len(field_list)}ê°œ")
                if field_list:
                    print(f"    ì˜ˆì‹œ: {field_list[:3]}")
        else:
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()