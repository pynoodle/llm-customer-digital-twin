"""
persona_json ë°ì´í„°ë¥¼ ë¸”ë¡ë³„ í”¼ì³ë¡œ ë³€í™˜í•˜ì—¬ ì„¤ë¬¸ëŒ€ìƒ ì„ ì •ìš© ë°ì´í„°ì…‹ ìƒì„±
"""

import pandas as pd
from datasets import load_dataset
import json
from collections import Counter
import numpy as np

def create_block_based_dataset():
    """persona_jsonì„ ë¸”ë¡ë³„ í”¼ì³ë¡œ ë³€í™˜í•œ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸš€ ë¸”ë¡ ê¸°ë°˜ ì„¤ë¬¸ëŒ€ìƒ ì„ ì •ìš© ë°ì´í„°ì…‹ ìƒì„±")
    print("="*60)
    
    # 1. ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ
    print("ğŸ“¦ ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = load_dataset("LLM-Digital-Twin/Twin-2K-500", "full_persona")
    df = dataset['data'].to_pandas()
    
    print(f"âœ… ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
    
    # 2. ëª¨ë“  ë¸”ë¡ ì´ë¦„ ìˆ˜ì§‘
    print("\nğŸ” ëª¨ë“  ë¸”ë¡ ì´ë¦„ ìˆ˜ì§‘ ì¤‘...")
    all_block_names = set()
    
    for idx, row in df.iterrows():
        try:
            parsed = json.loads(row['persona_json'])
            if isinstance(parsed, list):
                for block in parsed:
                    if isinstance(block, dict) and 'BlockName' in block:
                        all_block_names.add(block['BlockName'])
        except:
            pass
    
    print(f"âœ… ì´ {len(all_block_names)}ê°œì˜ ê³ ìœ  ë¸”ë¡ ë°œê²¬")
    
    # 3. ë¸”ë¡ë³„ í”¼ì³ ë°ì´í„° ìƒì„±
    print("\nğŸ“Š ë¸”ë¡ë³„ í”¼ì³ ë°ì´í„° ìƒì„± ì¤‘...")
    
    # ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼
    feature_columns = ['pid', 'persona_text', 'persona_summary']
    
    # ë¸”ë¡ ì¡´ì¬ ì—¬ë¶€ ì»¬ëŸ¼ (0/1)
    block_presence_columns = [f"has_{block_name.replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').lower()}" 
                             for block_name in sorted(all_block_names)]
    
    # ë¸”ë¡ë³„ ì§ˆë¬¸ ìˆ˜ ì»¬ëŸ¼
    block_question_count_columns = [f"questions_{block_name.replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').lower()}" 
                                  for block_name in sorted(all_block_names)]
    
    # ëª¨ë“  ì»¬ëŸ¼ ê²°í•©
    all_columns = feature_columns + block_presence_columns + block_question_count_columns
    
    # ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    new_data = []
    
    for idx, row in df.iterrows():
        record = {
            'pid': row.get('pid', idx),
            'persona_text': row.get('persona_text', ''),
            'persona_summary': row.get('persona_summary', '')
        }
        
        # ë¸”ë¡ ì •ë³´ ì´ˆê¸°í™”
        block_info = {block_name: {'present': 0, 'question_count': 0} 
                     for block_name in sorted(all_block_names)}
        
        try:
            parsed = json.loads(row['persona_json'])
            if isinstance(parsed, list):
                for block in parsed:
                    if isinstance(block, dict) and 'BlockName' in block:
                        block_name = block['BlockName']
                        if block_name in block_info:
                            block_info[block_name]['present'] = 1
                            block_info[block_name]['question_count'] = len(block.get('Questions', []))
        except:
            pass
        
        # ë¸”ë¡ ì •ë³´ë¥¼ ë ˆì½”ë“œì— ì¶”ê°€
        for block_name in sorted(all_block_names):
            safe_name = block_name.replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').lower()
            record[f"has_{safe_name}"] = block_info[block_name]['present']
            record[f"questions_{safe_name}"] = block_info[block_name]['question_count']
        
        new_data.append(record)
    
    # 4. ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    print("\nğŸ“‹ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘...")
    new_df = pd.DataFrame(new_data)
    
    print(f"âœ… ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:")
    print(f"  - ë ˆì½”ë“œ ìˆ˜: {len(new_df):,}")
    print(f"  - ì»¬ëŸ¼ ìˆ˜: {len(new_df.columns)}")
    print(f"  - ë¸”ë¡ í”¼ì³ ìˆ˜: {len(block_presence_columns)}")
    
    # 5. ë°ì´í„° ì €ì¥
    output_dir = "processed_dataset"
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # CSV ì €ì¥
    csv_path = os.path.join(output_dir, "block_based_dataset.csv")
    new_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {csv_path}")
    
    # 6. í†µê³„ ì •ë³´ ìƒì„±
    print("\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
    
    # ë¸”ë¡ë³„ ì¡´ì¬ ë¹„ìœ¨
    print(f"\nğŸ·ï¸ ë¸”ë¡ë³„ ì¡´ì¬ ë¹„ìœ¨ (ìƒìœ„ 20ê°œ):")
    block_stats = []
    for col in block_presence_columns:
        block_name = col.replace('has_', '').replace('_', ' ').title()
        presence_rate = new_df[col].mean() * 100
        block_stats.append((block_name, presence_rate, new_df[col].sum()))
    
    block_stats.sort(key=lambda x: x[1], reverse=True)
    
    for i, (block_name, rate, count) in enumerate(block_stats[:20], 1):
        print(f"  {i:2d}. {block_name:<40} {rate:5.1f}% ({count:,}ëª…)")
    
    # 7. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print(f"\nğŸ‘¤ ìƒ˜í”Œ ë°ì´í„° (ì²« ë²ˆì§¸ ë ˆì½”ë“œ):")
    sample_record = new_df.iloc[0]
    
    print(f"  - PID: {sample_record['pid']}")
    print(f"  - Persona Text: {sample_record['persona_text'][:100]}...")
    
    # ì¡´ì¬í•˜ëŠ” ë¸”ë¡ë“¤ë§Œ í‘œì‹œ
    present_blocks = []
    for col in block_presence_columns:
        if sample_record[col] == 1:
            block_name = col.replace('has_', '').replace('_', ' ').title()
            question_count = sample_record[f"questions_{col.replace('has_', '')}"]
            present_blocks.append((block_name, question_count))
    
    print(f"  - ì¡´ì¬í•˜ëŠ” ë¸”ë¡ ìˆ˜: {len(present_blocks)}")
    print(f"  - ë¸”ë¡ ëª©ë¡:")
    for block_name, q_count in present_blocks[:10]:  # ì²˜ìŒ 10ê°œë§Œ
        print(f"    â€¢ {block_name} ({q_count}ê°œ ì§ˆë¬¸)")
    if len(present_blocks) > 10:
        print(f"    ... ì™¸ {len(present_blocks) - 10}ê°œ ë¸”ë¡")
    
    # 8. í•„í„°ë§ ê°€ëŠ¥í•œ í”¼ì³ ëª©ë¡ ìƒì„±
    print(f"\nğŸ¯ ì„¤ë¬¸ëŒ€ìƒ ì„ ì •ìš© í”¼ì³ ëª©ë¡:")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    categories = {
        "í•µì‹¬_ë¸”ë¡": [
            "Demographics", "Personality", "Cognitive_tests", 
            "Economic_preferences", "Product_Preferences_Pricing"
        ],
        "ì‹¬ë¦¬í•™_ì‹¤í—˜": [
            "False_consensus", "Base_rate_30_engineers", "Base_rate_70_engineers",
            "Disease_loss", "Disease_gain", "Linda_conjunction", "Linda_no_conjunction",
            "Outcome_bias_success", "Outcome_bias_failure", "Anchoring_african_countries_high",
            "Anchoring_african_countries_low", "Anchoring_redwood_high", "Anchoring_redwood_low",
            "Sunk_cost_yes", "Sunk_cost_no", "Absolute_vs_relative_calculator",
            "Absolute_vs_relative_jacket", "Wta_wtp_thaler_problem_wta_certainty",
            "Wta_wtp_thaler_problem_wtp_certainty", "Wta_wtp_thaler_wtp_noncertainty",
            "Allais_form_1", "Allais_form_2", "Myside_german", "Myside_ford",
            "Probability_matching_vs_maximizing_problem_1", "Probability_matching_vs_maximizing_problem_2",
            "Non_experimental_heuristics_and_biases"
        ],
        "ê²Œì„_ì´ë¡ ": [
            "Less_is_more_gamble_a", "Less_is_more_gamble_b", "Less_is_more_gamble_c",
            "Proportion_dominance_1a", "Proportion_dominance_1b", "Proportion_dominance_1c",
            "Proportion_dominance_2a", "Proportion_dominance_2b", "Proportion_dominance_2c"
        ],
        "ê¸°íƒ€": ["Forward_flow"]
    }
    
    for category, blocks in categories.items():
        print(f"\nğŸ”¹ {category}:")
        available_blocks = []
        for block in blocks:
            safe_name = block.lower().replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '')
            has_col = f"has_{safe_name}"
            if has_col in new_df.columns:
                presence_rate = new_df[has_col].mean() * 100
                available_blocks.append((block, presence_rate))
        
        for block_name, rate in sorted(available_blocks, key=lambda x: x[1], reverse=True):
            print(f"  - {block_name}: {rate:.1f}%")
    
    # 9. ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'total_records': len(new_df),
        'total_columns': len(new_df.columns),
        'block_features': len(block_presence_columns),
        'question_count_features': len(block_question_count_columns),
        'unique_blocks': len(all_block_names),
        'block_list': sorted(list(all_block_names)),
        'categories': categories
    }
    
    metadata_path = os.path.join(output_dir, "block_dataset_metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“Š ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_path}")
    
    print(f"\nğŸ‰ ë¸”ë¡ ê¸°ë°˜ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ“„ ë©”ì¸ íŒŒì¼: block_based_dataset.csv")
    print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: block_dataset_metadata.json")
    
    return new_df, metadata

if __name__ == "__main__":
    try:
        dataset, metadata = create_block_based_dataset()
        print(f"\nâœ… ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
